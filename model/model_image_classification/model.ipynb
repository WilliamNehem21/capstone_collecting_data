{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:05:07.202663: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9747 images belonging to 9 classes.\n",
      "Found 3172 images belonging to 9 classes.\n",
      "Found 1670 images belonging to 9 classes.\n",
      "Found 3172 images belonging to 9 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:06:07.207969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamnehemia/anaconda3/envs/Capstone/lib/python3.11/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 24 16:20:13 2023\n",
    "\n",
    "@author: williamnehemia\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ConvNeXtXLarge\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "base_dir = '/Users/williamnehemia/Documents/Bangkit-Course/download_image/Fast Food Classification V2'\n",
    "#base_dir = '/Users/williamnehemia/Documents/Bangkit-Course/download_image/Fast_food_classification'\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "val_dir = os.path.join(base_dir, 'Valid')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    IMAGE_SIZE = [224, 224]\n",
    "\n",
    "    base =  ConvNeXtXLarge(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    prediction = Dense(9, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=prediction)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3),\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "# Create new model\n",
    "model_for_aug = create_model()\n",
    "\n",
    "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
    "# the image, we also rotate and do other operations\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_generator =  val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "test = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "val = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the new model\n",
    "history_with_aug = model_for_aug.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=30,\n",
    "      validation_data=val_generator,\n",
    "      validation_steps=100,  # 1000 images = batch_size * steps\n",
    "      verbose=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "def plot_loss_acc(history):\n",
    "  '''Plots the training and validation loss and accuracy from a history object'''\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()\n",
    "  \n",
    "  \n",
    "plot_loss_acc(history_with_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e5303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84f52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
